# 策略方法

正如前文所述，直接学习策略具有诸多优势，尤其是在状态空间或动作空间庞大或无限的应用场景中。如果动作空间是无限的，我们就无法进行策略提取，因为策略提取需要遍历所有动作并提取出能够最大化奖励的那个。直接学习策略可以缓解这一问题。

在本章中，我们将介绍两种基于策略的方法：

1. 策略迭代(Policy Iteration)：与值迭代类似，这是一种基于动态规划的方法，适用于基于模型的MDP。
2. 策略梯度(Policy Gradients)：这是一种无模型技术，执行梯度上升，其原理与众所周知的梯度下降技术相同，但目标是最大化奖励而非最小化误差。
